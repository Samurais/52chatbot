webpackJsonp([4,59],{364:function(n,t){n.exports={rawContent:"\n使用神经网络完成分类，物体识别，序列化标注，问答，生成式对话、翻译、摘要已成为标准手段，在训练神经网络时，一个很难的地方是怎么调试网络的超参数，超参数影响了网络的收敛速度，也影响最终的结果。\n\n我们假设数据和算法都定了，数据也准备好了。这时候，在网络初始化阶段，Weights和Biases是随机初始化的。那么还剩下一些参数，比如隐含层的设计、mini batch size、learning rate。调试超参数是使用控制变量法，以下是一些参考建议：\n\n\n## 使用一个规模比较小的数据集来调试超参数\n\n在常见的规范的开放数据集中，都是将数据集分成三份：train, test和validation。\n\ntrain就是训练时候使用的，test是作为最终评测使用的，而validation就是用作调试超参数的。train和validation 也被称为开发数据集。有的数据集不设validation数据集，是因为数据量小，通常可以用train数据集做调试超参数。\n\n所以，假设我们有了一个validation数据集，这个数据集数据不易太多，因为数据越多，越需要多次迭代才能看到超参数的效果，需要的时间就越长：在Fitting阶段，需要比较不同参数下损失变化的曲线和精度的值。\n\n## 调试 learning rate\n在其它超参数保持不变的情况下，改变学习率，比如从0.0001开始，然后顺序选择0.001, 0.01, 0.05, 0.1, 0.5。然后比较不同学习率下损失函数的曲线增长或减少的幅度。我们可以找到一个区间，也就是在这个区间内，损失函数的波形是稳定下降的，不会发生振荡。那么，取这个区间内的值就可以。\n\n\n## 调试 batch size\n在其它超参数保持不变的情况下，改变batch size, 比如依次选择20, 50, 100, 200。然后比较不同batch size下，能使准确率变化最陡的值。准确率变化越陡，证明参数学习收敛越快，\n\n## 调试 隐含层\n在其它超参数保持不变的情况下，改变隐含层层数或每层神经元多少，选择能取得最高的准确率的值。\n\n## 总结\n\n调节超参数使用控制变量法，按照上述顺序进行。\n\n\n\n\n",metaData:{layout:"post",title:"深度学习：调节网络超参数",excerpt:"在训练前，需要先规划超级参数，比如batch size, etc.",category:"development",tags:["deeplearning"],disqus:!0}}}});