webpackJsonp([5,43],{324:function(t,n){t.exports={rawContent:'\n> Original post: https://handong1587.github.io/\n\n# Tutorials\n\n![](/assets/deep_learning/NLP/Deep Learning For NLP.jpg)\n\n**Practical Neural Networks for NLP**\n\n- intro: EMNLP 2016\n- github: [https://github.com/clab/dynet_tutorial_examples](https://github.com/clab/dynet_tutorial_examples)\n\n**Structured Neural Networks for NLP: From Idea to Code**\n\n- slides: [https://github.com/neubig/yrsnlp-2016/blob/master/neubig16yrsnlp.pdf](https://github.com/neubig/yrsnlp-2016/blob/master/neubig16yrsnlp.pdf)\n- github: [https://github.com/neubig/yrsnlp-2016](https://github.com/neubig/yrsnlp-2016)\n\n**Understanding Deep Learning Models in NLP**\n\n[http://nlp.yvespeirsman.be/blog/understanding-deeplearning-models-nlp/](http://nlp.yvespeirsman.be/blog/understanding-deeplearning-models-nlp/)\n\n**Deep learning for natural language processing, Part 1**\n\n[https://softwaremill.com/deep-learning-for-nlp/](https://softwaremill.com/deep-learning-for-nlp/)\n\n# Neural Models\n\n**Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models**\n\n![](/assets/dl-materials/Unifying_Visual-Semantic_Embeddings_with_Multimodal_Neural_Language_Models.png)\n\n- arxiv: [http://arxiv.org/abs/1411.2539](http://arxiv.org/abs/1411.2539)\n- github: [https://github.com/ryankiros/visual-semantic-embedding](https://github.com/ryankiros/visual-semantic-embedding)\n- results: [http://www.cs.toronto.edu/~rkiros/lstm_scnlm.html](http://www.cs.toronto.edu/~rkiros/lstm_scnlm.html)\n- demo: [http://deeplearning.cs.toronto.edu/i2t](http://deeplearning.cs.toronto.edu/i2t)\n\n**Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks**\n\n- arxiv: [http://arxiv.org/abs/1503.00075](http://arxiv.org/abs/1503.00075)\n- github: [https://github.com/stanfordnlp/treelstm](https://github.com/stanfordnlp/treelstm)\n- github(Theano): [https://github.com/ofirnachum/tree_rnn](https://github.com/ofirnachum/tree_rnn)\n\n**Visualizing and Understanding Neural Models in NLP**\n\n![](https://camo.githubusercontent.com/bd5126b7abf6c3dfa50ca1cd5c93fc559ec9eb35/687474703a2f2f7374616e666f72642e6564752f2537456a697765696c2f76697375616c312e706e67)\n\n- arxiv: [http://arxiv.org/abs/1506.01066](http://arxiv.org/abs/1506.01066)\n- github: [https://github.com/jiweil/Visualizing-and-Understanding-Neural-Models-in-NLP](https://github.com/jiweil/Visualizing-and-Understanding-Neural-Models-in-NLP)\n\n**Character-Aware Neural Language Models**\n\n- paper: [http://arxiv.org/abs/1508.06615](http://arxiv.org/abs/1508.06615)\n- github: [https://github.com/yoonkim/lstm-char-cnn](https://github.com/yoonkim/lstm-char-cnn)\n\n**Skip-Thought Vectors**\n\n- paper: [http://arxiv.org/abs/1506.06726](http://arxiv.org/abs/1506.06726)\n- github: [https://github.com/ryankiros/skip-thoughts](https://github.com/ryankiros/skip-thoughts)\n\n**A Primer on Neural Network Models for Natural Language Processing**\n\n- arxiv: [http://arxiv.org/abs/1510.00726](http://arxiv.org/abs/1510.00726)\n\n**Character-aware Neural Language Models**\n\n- arxiv: [http://arxiv.org/abs/1508.06615](http://arxiv.org/abs/1508.06615)\n\n**Neural Variational Inference for Text Processing**\n\n- arxiv: [http://arxiv.org/abs/1511.06038](http://arxiv.org/abs/1511.06038)\n- notes: [http://dustintran.com/blog/neural-variational-inference-for-text-processing/](http://dustintran.com/blog/neural-variational-inference-for-text-processing/)\n- github: [https://github.com/carpedm20/variational-text-tensorflow](https://github.com/carpedm20/variational-text-tensorflow)\n- github: [https://github.com/cheng6076/NVDM](https://github.com/cheng6076/NVDM)\n\n# Sequence to Sequence Learning\n\n**Generating Text with Deep Reinforcement Learning**\n\n- intro: NIPS 2015\n- arxiv: [http://arxiv.org/abs/1510.09202](http://arxiv.org/abs/1510.09202)\n\n**MUSIO: A Deep Learning based Chatbot Getting Smarter**\n\n- homepage: [http://ec2-204-236-149-143.us-west-1.compute.amazonaws.com:9000/](http://ec2-204-236-149-143.us-west-1.compute.amazonaws.com:9000/)\n- github(Torch7): [https://github.com/deepcoord/seq2seq](https://github.com/deepcoord/seq2seq)\n\n# Translation\n\n**Learning phrase representations using rnn encoder-decoder for statistical machine translation**\n\n- intro: GRU. EMNLP 2014\n- arxiv: [http://arxiv.org/abs/1406.1078](http://arxiv.org/abs/1406.1078)\n\n**Neural Machine Translation by Jointly Learning to Align and Translate**\n\n- intro: ICLR 2015\n- arxiv: [http://arxiv.org/abs/1409.0473](http://arxiv.org/abs/1409.0473)\n- github: [https://github.com/lisa-groundhog/GroundHog](https://github.com/lisa-groundhog/GroundHog)\n\n**Multi-Source Neural Translation**\n\n- intro: "report up to +4.8 Bleu increases on top of a very strong attention-based neural translation model."\n- arxiv: [Multi-Source Neural Translation](Multi-Source Neural Translation)\n- github(Zoph_RNN): [https://github.com/isi-nlp/Zoph_RNN](https://github.com/isi-nlp/Zoph_RNN)\n- video: [http://research.microsoft.com/apps/video/default.aspx?id=260336](http://research.microsoft.com/apps/video/default.aspx?id=260336)\n\n**Multi-Way, Multilingual Neural Machine Translation with a Shared Attention Mechanism**\n\n- arxiv: [http://arxiv.org/abs/1601.01073](http://arxiv.org/abs/1601.01073)\n- github: [https://github.com/nyu-dl/dl4mt-multi](https://github.com/nyu-dl/dl4mt-multi)\n- notes: [https://github.com/dennybritz/deeplearning-papernotes/blob/master/notes/multi-way-nmt-shared-attention.md](https://github.com/dennybritz/deeplearning-papernotes/blob/master/notes/multi-way-nmt-shared-attention.md)\n\n**Modeling Coverage for Neural Machine Translation**\n\n- arxiv: [http://arxiv.org/abs/1601.04811](http://arxiv.org/abs/1601.04811)\n\n**A Character-level Decoder without Explicit Segmentation for Neural Machine Translation**\n\n- arxiv: [http://arxiv.org/abs/1603.06147](http://arxiv.org/abs/1603.06147)\n- github: [https://github.com/nyu-dl/dl4mt-cdec](https://github.com/nyu-dl/dl4mt-cdec)\n\n**NEMATUS: Attention-based encoder-decoder model for neural machine translation**\n\n- github: [https://github.com/rsennrich/nematus](https://github.com/rsennrich/nematus)\n\n**Variational Neural Machine Translation**\n\n- intro: EMNLP 2016\n- arxiv: [https://arxiv.org/abs/1605.07869](https://arxiv.org/abs/1605.07869)\n- github: [https://github.com/DeepLearnXMU/VNMT](https://github.com/DeepLearnXMU/VNMT)\n\n**Neural Network Translation Models for Grammatical Error Correction**\n\n- arxiv: [http://arxiv.org/abs/1606.00189](http://arxiv.org/abs/1606.00189)\n\n**Linguistic Input Features Improve Neural Machine Translation**\n\n- arxiv: [http://arxiv.org/abs/1606.02892](http://arxiv.org/abs/1606.02892)\n- github: [https://github.com/rsennrich/nematus](https://github.com/rsennrich/nematus)\n\n**Sequence-Level Knowledge Distillation**\n\n- intro: EMNLP 2016\n- arxiv: [http://arxiv.org/abs/1606.07947](http://arxiv.org/abs/1606.07947)\n- github: [https://github.com/harvardnlp/nmt-android](https://github.com/harvardnlp/nmt-android)\n\n**Neural Machine Translation: Breaking the Performance Plateau**\n\n- slides: [http://www.meta-net.eu/events/meta-forum-2016/slides/09_sennrich.pdf](http://www.meta-net.eu/events/meta-forum-2016/slides/09_sennrich.pdf)\n\n**Tips on Building Neural Machine Translation Systems**\n\n- github: [https://github.com/neubig/nmt-tips](https://github.com/neubig/nmt-tips)\n\n**Semi-Supervised Learning for Neural Machine Translation**\n\n- intro: ACL 2016. Tsinghua University & Baidu Inc\n- arxiv: [http://arxiv.org/abs/1606.04596](http://arxiv.org/abs/1606.04596)\n\n**EUREKA-MangoNMT: A C++ toolkit for neural machine translation for CPU**\n\n- github: [https://github.com/jiajunzhangnlp/EUREKA-MangoNMT](https://github.com/jiajunzhangnlp/EUREKA-MangoNMT)\n\n**Deep Character-Level Neural Machine Translation**\n\n![](https://raw.githubusercontent.com/SwordYork/DCNMT/master/dcnmt.png)\n\n- github: [https://github.com/SwordYork/DCNMT](https://github.com/SwordYork/DCNMT)\n\n**Neural Machine Translation Implementations**\n\n- github: [https://github.com/jonsafari/nmt-list](https://github.com/jonsafari/nmt-list)\n\n**Google\'s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation**\n\n- arxiv: [http://arxiv.org/abs/1609.08144v1](http://arxiv.org/abs/1609.08144v1)\n\n**Learning to Translate in Real-time with Neural Machine Translation**\n\n- arxiv: [https://arxiv.org/abs/1610.00388](https://arxiv.org/abs/1610.00388)\n\n**Is Neural Machine Translation Ready for Deployment? A Case Study on 30 Translation Directions**\n\n- arxiv: [https://arxiv.org/abs/1610.01108](https://arxiv.org/abs/1610.01108)\n- github: [https://github.com/emjotde/amunmt](https://github.com/emjotde/amunmt)\n\n**Fully Character-Level Neural Machine Translation without Explicit Segmentation**\n\n- arxiv: [https://arxiv.org/abs/1610.03017](https://arxiv.org/abs/1610.03017)\n- github: [https://github.com/nyu-dl/dl4mt-c2c](https://github.com/nyu-dl/dl4mt-c2c)\n\n**Navigational Instruction Generation as Inverse Reinforcement Learning with Neural Machine Translation**\n\n- arxiv: [https://arxiv.org/abs/1610.03164](https://arxiv.org/abs/1610.03164)\n\n**Neural Machine Translation in Linear Time**\n\n- intro: ByteNet\n- arxiv: [https://arxiv.org/abs/1610.10099](https://arxiv.org/abs/1610.10099)\n- github: [https://github.com/paarthneekhara/byteNet-tensorflow](https://github.com/paarthneekhara/byteNet-tensorflow)\n- github(Tensorflow): [https://github.com/buriburisuri/ByteNet](https://github.com/buriburisuri/ByteNet)\n\n**Neural Machine Translation with Reconstruction**\n\n- arxiv: [https://arxiv.org/abs/1611.01874](https://arxiv.org/abs/1611.01874)\n\n**A Convolutional Encoder Model for Neural Machine Translation**\n\n- intro: Facebook AI Research\n- arxiv: [https://arxiv.org/abs/1611.02344](https://arxiv.org/abs/1611.02344)\n\n**Toward Multilingual Neural Machine Translation with Universal Encoder and Decoder**\n\n- arxiv: [https://arxiv.org/abs/1611.04798](https://arxiv.org/abs/1611.04798)\n\n**MXNMT: MXNet based Neural Machine Translation**\n\n- github: [https://github.com/magic282/MXNMT](https://github.com/magic282/MXNMT)\n\n**Doubly-Attentive Decoder for Multi-modal Neural Machine Translation**\n\n- intro: Dublin City University & Trinity College Dublin\n- arxiv: [https://arxiv.org/abs/1702.01287](https://arxiv.org/abs/1702.01287)\n\n**Massive Exploration of Neural Machine Translation Architectures**\n\n- intro: Google Brain\n- arxiv: [https://arxiv.org/abs/1703.03906](https://arxiv.org/abs/1703.03906)\n- github: [https://github.com/google/seq2seq/](https://github.com/google/seq2seq/)\n\n**Depthwise Separable Convolutions for Neural Machine Translation**\n\n- intro: Google Brain & University of Toronto\n- arxiv: [https://arxiv.org/abs/1706.03059](https://arxiv.org/abs/1706.03059)\n\n# Summarization\n\n**Extraction of Salient Sentences from Labelled Documents**\n\n- arxiv: [http://arxiv.org/abs/1412.6815](http://arxiv.org/abs/1412.6815)\n- github: [https://github.com/mdenil/txtnets](https://github.com/mdenil/txtnets)\n- notes: [https://github.com/jxieeducation/DIY-Data-Science/blob/master/papernotes/2014/06/model-visualizing-summarising-conv-net.md](https://github.com/jxieeducation/DIY-Data-Science/blob/master/papernotes/2014/06/model-visualizing-summarising-conv-net.md)\n\n**A Neural Attention Model for Abstractive Sentence Summarization**\n\n- intro: EMNLP 2015. Facebook AI Research\n- arxiv: [http://arxiv.org/abs/1509.00685](http://arxiv.org/abs/1509.00685)\n- github: [https://github.com/facebook/NAMAS](https://github.com/facebook/NAMAS)\n- github(TensorFlow): [https://github.com/carpedm20/neural-summary-tensorflow](https://github.com/carpedm20/neural-summary-tensorflow)\n\n**A Convolutional Attention Network for Extreme Summarization of Source Code**\n\n![](https://camo.githubusercontent.com/95dfe4b12b966b664fd441b19430405520a859a9/687474703a2f2f7333322e706f7374696d672e6f72672f7263326664793079642f53637265656e5f53686f745f323031365f30355f30395f61745f31305f31385f33365f504d2e706e67)\n\n- homepage: [http://groups.inf.ed.ac.uk/cup/codeattention/](http://groups.inf.ed.ac.uk/cup/codeattention/)\n- arxiv: [http://arxiv.org/abs/1602.03001](http://arxiv.org/abs/1602.03001)\n- github: [https://github.com/jxieeducation/DIY-Data-Science/blob/master/papernotes/2016/02/conv-attention-network-source-code-summarization.md](https://github.com/jxieeducation/DIY-Data-Science/blob/master/papernotes/2016/02/conv-attention-network-source-code-summarization.md)\n\n**Abstractive Text Summarization Using Sequence-to-Sequence RNNs and Beyond**\n\n- intro: BM Watson & Université de Montréal\n- arxiv: [http://arxiv.org/abs/1602.06023](http://arxiv.org/abs/1602.06023)\n\n**textsum: Text summarization with TensorFlow**\n\n- blog: [https://research.googleblog.com/2016/08/text-summarization-with-tensorflow.html](https://research.googleblog.com/2016/08/text-summarization-with-tensorflow.html)\n- github: [https://github.com/tensorflow/models/tree/master/textsum](https://github.com/tensorflow/models/tree/master/textsum)\n\n**How to Run Text Summarization with TensorFlow**\n\n- blog: [https://medium.com/@surmenok/how-to-run-text-summarization-with-tensorflow-d4472587602d#.mll1rqgjg](https://medium.com/@surmenok/how-to-run-text-summarization-with-tensorflow-d4472587602d#.mll1rqgjg)\n- github: [https://github.com/surmenok/TextSum](https://github.com/surmenok/TextSum)\n\n# Reading Comprehension\n\n**Text Comprehension with the Attention Sum Reader Network**\n\n**Text Understanding with the Attention Sum Reader Network**\n\n- intro: ACL 2016\n- arxiv: [https://arxiv.org/abs/1603.01547](https://arxiv.org/abs/1603.01547)\n- github: [https://github.com/rkadlec/asreader](https://github.com/rkadlec/asreader)\n\n**A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task**\n\n- arxiv: [http://arxiv.org/abs/1606.02858](http://arxiv.org/abs/1606.02858)\n- github: [https://github.com/danqi/rc-cnn-dailymail](https://github.com/danqi/rc-cnn-dailymail)\n\n**Consensus Attention-based Neural Networks for Chinese Reading Comprehension**\n\n- arxiv: [http://arxiv.org/abs/1607.02250](http://arxiv.org/abs/1607.02250)\n- dataset("HFL-RC"): [http://hfl.iflytek.com/chinese-rc/](http://hfl.iflytek.com/chinese-rc/)\n\n**Separating Answers from Queries for Neural Reading Comprehension**\n\n- arxiv: [http://arxiv.org/abs/1607.03316](http://arxiv.org/abs/1607.03316)\n- github: [https://github.com/dirkweissenborn/qa_network](https://github.com/dirkweissenborn/qa_network)\n\n**Attention-over-Attention Neural Networks for Reading Comprehension**\n\n- arxiv: [http://arxiv.org/abs/1607.04423](http://arxiv.org/abs/1607.04423)\n- github: [https://github.com/OlavHN/attention-over-attention](https://github.com/OlavHN/attention-over-attention)\n\n**Teaching Machines to Read and Comprehend CNN News and Children Books using Torch**\n\n- github: [https://github.com/ganeshjawahar/torch-teacher](https://github.com/ganeshjawahar/torch-teacher)\n\n**Reasoning with Memory Augmented Neural Networks for Language Comprehension**\n\n- arxiv: [https://arxiv.org/abs/1610.06454](https://arxiv.org/abs/1610.06454)\n\n**Bidirectional Attention Flow: Bidirectional Attention Flow for Machine Comprehension**\n\n- project page: [https://allenai.github.io/bi-att-flow/](https://allenai.github.io/bi-att-flow/)\n- github: [https://github.com/allenai/bi-att-flow](https://github.com/allenai/bi-att-flow)\n\n**NewsQA: A Machine Comprehension Dataset**\n\n- arxiv: [https://arxiv.org/abs/1611.09830](https://arxiv.org/abs/1611.09830)\n- dataset: [http://datasets.maluuba.com/NewsQA](http://datasets.maluuba.com/NewsQA)\n- github: [https://github.com/Maluuba/newsqa](https://github.com/Maluuba/newsqa)\n\n**Gated-Attention Readers for Text Comprehension**\n\n- intro: CMU\n- arxiv: [https://arxiv.org/abs/1606.01549](https://arxiv.org/abs/1606.01549)\n- github: [https://github.com/bdhingra/ga-reader](https://github.com/bdhingra/ga-reader)\n\n**Get To The Point: Summarization with Pointer-Generator Networks**\n\n- intro: ACL 2017. Stanford University & Google Brain\n- arxiv: [https://arxiv.org/abs/1704.04368](https://arxiv.org/abs/1704.04368)\n- github: [https://github.com/abisee/pointer-generator](https://github.com/abisee/pointer-generator)\n\n# Question Answering\n\n**Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks**\n\n- intro: Facebook AI Research\n- arxiv: [http://arxiv.org/abs/1502.05698v1](http://arxiv.org/abs/1502.05698v1)\n- github: [https://github.com/facebook/bAbI-tasks](https://github.com/facebook/bAbI-tasks)\n\n**VQA: Visual Question Answering**\n\n- intro: ICCV 2015\n- arxiv: [http://arxiv.org/abs/1505.00468](http://arxiv.org/abs/1505.00468)\n- homepage: [http://visualqa.org/](http://visualqa.org/)\n\n**Ask Your Neurons: A Neural-based Approach to Answering Questions about Images**\n\n- intro: ICCV 2015\n- arxiv: [http://arxiv.org/abs/1505.01121](http://arxiv.org/abs/1505.01121)\n- project: [https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/research/vision-and-language/visual-turing-challenge/](https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/research/vision-and-language/visual-turing-challenge/)\n- video: [https://www.youtube.com/watch?v=QZEwDcN8ehs&hd=1](https://www.youtube.com/watch?v=QZEwDcN8ehs&hd=1)\n\n**Exploring Models and Data for Image Question Answering**\n\n![](https://camo.githubusercontent.com/ac498616bb6ea1db7aaabb1cf567d07e4bbef395/687474703a2f2f692e696d6775722e636f6d2f4a7669787832572e6a7067)\n\n- arxiv: [http://arxiv.org/abs/1505.02074](http://arxiv.org/abs/1505.02074)\n- gtihub(Tensorflow): [https://github.com/paarthneekhara/neural-vqa-tensorflow](https://github.com/paarthneekhara/neural-vqa-tensorflow)\n- github(Python+Keras): [https://github.com/ayushoriginal/NeuralNetwork-ImageQA](https://github.com/ayushoriginal/NeuralNetwork-ImageQA)\n\n**Are You Talking to a Machine? Dataset and Methods for Multilingual Image Question Answering**\n\n- arxiv: [http://arxiv.org/abs/1505.05612](http://arxiv.org/abs/1505.05612)\n\n**Teaching Machines to Read and Comprehend**\n\n- intro: Google DeepMind\n- arxiv: [http://arxiv.org/abs/1506.03340](http://arxiv.org/abs/1506.03340)\n- github: [https://github.com/deepmind/rc-data](https://github.com/deepmind/rc-data)\n- github(Theano/Blocks): [https://github.com/thomasmesnard/DeepMind-Teaching-Machines-to-Read-and-Comprehend](https://github.com/thomasmesnard/DeepMind-Teaching-Machines-to-Read-and-Comprehend)\n- github(Tensorflow): [https://github.com/carpedm20/attentive-reader-tensorflow](https://github.com/carpedm20/attentive-reader-tensorflow)\n\n**Neural Module Networks**\n\n- intro: CVPR 2016\n- arxiv: [http://arxiv.org/abs/1511.02799](http://arxiv.org/abs/1511.02799)\n- github: [https://github.com/jacobandreas/nmn2](https://github.com/jacobandreas/nmn2)\n\n**Image Question Answering using Convolutional Neural Network with Dynamic Parameter Prediction**\n\n![](http://cvlab.postech.ac.kr/research/dppnet/images/figure2.png)\n\n- arxiv: [http://arxiv.org/abs/1511.05756](http://arxiv.org/abs/1511.05756)\n- github: [https://github.com/HyeonwooNoh/DPPnet](https://github.com/HyeonwooNoh/DPPnet)\n- project page: [http://cvlab.postech.ac.kr/research/dppnet/](http://cvlab.postech.ac.kr/research/dppnet/)\n\n**Neural Generative Question Answering**\n\n- arxiv: [http://arxiv.org/abs/1512.01337](http://arxiv.org/abs/1512.01337)\n\n**Stacked Attention Networks for Image Question Answering**\n\n- arxiv: [http://arxiv.org/abs/1511.02274](http://arxiv.org/abs/1511.02274)\n- github: [https://github.com/abhshkdz/neural-vqa-attention](https://github.com/abhshkdz/neural-vqa-attention)\n\n**Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering**\n\n- arxiv: [http://arxiv.org/abs/1511.05234](http://arxiv.org/abs/1511.05234)\n\n**Simple Baseline for Visual Question Answering**\n\n- intro: Facebook AI Research. Bag-of-word\n- arxiv: [http://arxiv.org/abs/1512.02167](http://arxiv.org/abs/1512.02167)\n- github: [https://github.com/metalbubble/VQAbaseline](https://github.com/metalbubble/VQAbaseline)\n- demo: [http://visualqa.csail.mit.edu/](http://visualqa.csail.mit.edu/)\n\n**MovieQA: Understanding Stories in Movies through Question-Answering**\n\n- intro: CVPR 2016\n- project page: [http://movieqa.cs.toronto.edu/home/](http://movieqa.cs.toronto.edu/home/)\n- arxiv: [http://arxiv.org/abs/1512.02902](http://arxiv.org/abs/1512.02902)\n- gtihub: [https://github.com/makarandtapaswi/MovieQA_CVPR2016/](https://github.com/makarandtapaswi/MovieQA_CVPR2016/)\n\n**Deeper LSTM+ normalized CNN for Visual Question Answering**\n\n- intro: "This current code can get 58.16 on Open-Ended and 63.09 on Multiple-Choice on test-standard split"\n- github: [https://github.com/VT-vision-lab/VQA_LSTM_CNN](https://github.com/VT-vision-lab/VQA_LSTM_CNN)\n\n**A Neural Network for Factoid Question Answering over Paragraphs**\n\n- project page: [http://cs.umd.edu/~miyyer/qblearn/](http://cs.umd.edu/~miyyer/qblearn/)\n- paper: [https://cs.umd.edu/~miyyer/pubs/2014_qb_rnn.pdf](https://cs.umd.edu/~miyyer/pubs/2014_qb_rnn.pdf)\n- code+data: [https://cs.umd.edu/~miyyer/qblearn/qanta.tar.gz](https://cs.umd.edu/~miyyer/qblearn/qanta.tar.gz)\n\n**Learning to Compose Neural Networks for Question Answering**\n\n- intro: NAACL 2016 Best paper\n- arxiv: [http://arxiv.org/abs/1601.01705](http://arxiv.org/abs/1601.01705)\n\n**Generating Natural Questions About an Image**\n\n- arxiv: [http://arxiv.org/abs/1603.06059](http://arxiv.org/abs/1603.06059)\n\n**Question Answering on Freebase via Relation Extraction and Textual Evidence**\n\n- intro: ACL 2016\n- arxiv: [https://arxiv.org/abs/1603.00957](https://arxiv.org/abs/1603.00957)\n- github: [https://github.com/syxu828/QuestionAnsweringOverFB](https://github.com/syxu828/QuestionAnsweringOverFB)\n\n**Generating Factoid Questions With Recurrent Neural Networks: The 30M Factoid Question-Answer Corpus**\n\n- arxiv: [http://arxiv.org/abs/1603.06807](http://arxiv.org/abs/1603.06807)\n\n**Character-Level Question Answering with Attention**\n\n- arxiv: [http://arxiv.org/abs/1604.00727](http://arxiv.org/abs/1604.00727)\n- comment(by @Wenpeng_Yin): "fancy model with minor improvement"\n\n**A Focused Dynamic Attention Model for Visual Question Answering**\n\n- arxiv: [http://arxiv.org/abs/1604.01485](http://arxiv.org/abs/1604.01485)\n\n**Visual Question Answering Literature Survey**\n\n- blog: [http://iamaaditya.github.io/research/literature/](http://iamaaditya.github.io/research/literature/)\n\n**The DIY Guide to Visual Question Answering**\n\n![](https://camo.githubusercontent.com/53c28e13bd645acbf49c9e71e82a36202d1981bc/687474703a2f2f7333322e706f7374696d672e6f72672f77636a6c7a7a7532742f53637265656e5f53686f745f323031365f30355f30385f61745f325f34325f30375f504d2e706e67)\n\n- github: [https://github.com/jxieeducation/DIY-Data-Science/blob/master/research/visual_qa.md](https://github.com/jxieeducation/DIY-Data-Science/blob/master/research/visual_qa.md)\n\n**Question Answering via Integer Programming over Semi-Structured Knowledge**\n\n- arxiv: [http://arxiv.org/abs/1604.06076](http://arxiv.org/abs/1604.06076)\n- github: [https://github.com/allenai/tableilp](https://github.com/allenai/tableilp)\n- youtube: [https://www.youtube.com/watch?v=7NS53icQRrs](https://www.youtube.com/watch?v=7NS53icQRrs)\n\n**Hierarchical Question-Image Co-Attention for Visual Question Answering**\n\n- arxiv: [http://arxiv.org/abs/1606.00061](http://arxiv.org/abs/1606.00061)\n- github: [https://github.com/jiasenlu/HieCoAttenVQA](https://github.com/jiasenlu/HieCoAttenVQA)\n\n**Multimodal Residual Learning for Visual QA**\n\n- arxiv: [http://arxiv.org/abs/1606.01455](http://arxiv.org/abs/1606.01455)\n\n**Simple Question Answering by Attentive Convolutional Neural Network**\n\n- arxiv: [http://arxiv.org/abs/1606.03391](http://arxiv.org/abs/1606.03391)\n\n**Human Attention in Visual Question Answering: Do Humans and Deep Networks Look at the Same Regions?**\n\n![](https://computing.ece.vt.edu/~abhshkdz/vqa-hat/img/att_comparison_2row.jpg)\n\n- homepage: [https://computing.ece.vt.edu/~abhshkdz/vqa-hat/](https://computing.ece.vt.edu/~abhshkdz/vqa-hat/)\n- arxiv: [http://arxiv.org/abs/1606.03556](http://arxiv.org/abs/1606.03556)\n\n**Simple and Effective Question Answering with Recurrent Neural Networks**\n\n- arxiv: [http://arxiv.org/abs/1606.05029](http://arxiv.org/abs/1606.05029)\n\n**Analyzing the Behavior of Visual Question Answering Models**\n\n- arxiv: [http://arxiv.org/abs/1606.07356](http://arxiv.org/abs/1606.07356)\n\n**Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding**\n\n- arxiv: [https://arxiv.org/abs/1606.01847](https://arxiv.org/abs/1606.01847)\n- github: [https://github.com/akirafukui/vqa-mcb](https://github.com/akirafukui/vqa-mcb)\n\n**Deep Language Modeling for Question Answering using Keras**\n\n- blog: [http://benjaminbolte.com/blog/2016/keras-language-modeling.html](http://benjaminbolte.com/blog/2016/keras-language-modeling.html)\n- github: [https://github.com/codekansas/keras-language-modeling](https://github.com/codekansas/keras-language-modeling)\n\n**Interpreting Visual Question Answering Models**\n\n- arxiv: [http://arxiv.org/abs/1608.08974](http://arxiv.org/abs/1608.08974)\n\n**The Color of the Cat is Gray: 1 Million Full-Sentences Visual Question Answering**\n\n- intro: FSVQA\n- arxiv: [http://arxiv.org/abs/1609.06657](http://arxiv.org/abs/1609.06657)\n\n**Tutorial on Answering Questions about Images with Deep Learning**\n\n- intro: The tutorial was presented at \'2nd Summer School on Integrating Vision and Language: Deep Learning\' in Malta, 2016\n- arxiv: [https://arxiv.org/abs/1610.01076](https://arxiv.org/abs/1610.01076)\n\n**Hadamard Product for Low-rank Bilinear Pooling**\n\n- arxiv: [https://arxiv.org/abs/1610.04325](https://arxiv.org/abs/1610.04325)\n- github: [https://github.com/jnhwkim/MulLowBiVQA](https://github.com/jnhwkim/MulLowBiVQA)\n\n**Open-Ended Visual Question-Answering**\n\n![](https://raw.githubusercontent.com/imatge-upc/vqa-2016-cvprw/gh-pages/img/model.jpg)\n\n- intro: Bachelor thesis report graded with A with honours at ETSETB Telecom BCN school, Universitat Polit\\`ecnica de Catalunya (UPC). June 2016\n- project page: [http://imatge-upc.github.io/vqa-2016-cvprw/](http://imatge-upc.github.io/vqa-2016-cvprw/)\n- arxiv: [https://arxiv.org/abs/1610.02692](https://arxiv.org/abs/1610.02692)\n- slides: [http://www.slideshare.net/xavigiro/openended-visual-questionanswering](http://www.slideshare.net/xavigiro/openended-visual-questionanswering)\n- github: [https://github.com/imatge-upc/vqa-2016-cvprw](https://github.com/imatge-upc/vqa-2016-cvprw)\n\n**Deep Learning for Question Answering**\n\n- intro: UMD. Mohit Iyyer. \n- intro: Recurrent Neural Networks, Recursive Neural Network\n- slides: [http://cs.umd.edu/~miyyer/data/deepqa.pdf](http://cs.umd.edu/~miyyer/data/deepqa.pdf)\n\n**Dual Attention Networks for Multimodal Reasoning and Matching**\n\n- arxiv: [https://arxiv.org/abs/1611.00471](https://arxiv.org/abs/1611.00471)\n\n**Leveraging Video Descriptions to Learn Video Question Answering**\n\n- intro: AAAI 2017\n- arxiv: [https://arxiv.org/abs/1611.04021](https://arxiv.org/abs/1611.04021)\n\n**Dynamic Coattention Networks For Question Answering**\n\n- arxiv: [https://arxiv.org/abs/1611.01604](https://arxiv.org/abs/1611.01604)\n\n**State of the art deep learning model for question answering**\n\n- blog: [http://metamind.io/research/state-of-the-art-deep-learning-model-for-question-answering/](http://metamind.io/research/state-of-the-art-deep-learning-model-for-question-answering/)\n\n**Zero-Shot Visual Question Answering**\n\n- arxiv: [https://arxiv.org/abs/1611.05546](https://arxiv.org/abs/1611.05546)\n\n**Image-Grounded Conversations: Multimodal Context for Natural Question and Response Generation**\n\n- intro: University of Rochester & Microsoft & University College London\n- arxiv: [https://arxiv.org/abs/1701.08251](https://arxiv.org/abs/1701.08251)\n\n**Question Answering through Transfer Learning from Large Fine-grained Supervision Data**\n\n- intro: Seoul National University & University of Washington\n- arxiv: [https://arxiv.org/abs/1702.02171](https://arxiv.org/abs/1702.02171)\n\n**Question Answering from Unstructured Text by Retrieval and Comprehension**\n\n- arxiv: [https://arxiv.org/abs/1703.08885](https://arxiv.org/abs/1703.08885)\n- notes: [https://theneuralperspective.com/2017/04/26/question-answering-from-unstructured-text-by-retrieval-and-comprehension/](https://theneuralperspective.com/2017/04/26/question-answering-from-unstructured-text-by-retrieval-and-comprehension/)\n\n**Show, Ask, Attend, and Answer: A Strong Baseline For Visual Question Answering**\n\n- intro: Google Research\n- arxiv: [https://arxiv.org/abs/1704.03162](https://arxiv.org/abs/1704.03162)\n\n**Learning to Reason: End-to-End Module Networks for Visual Question Answering**\n\n- intro: UC Berkeley, Boston University\n- arxiv: [https://arxiv.org/abs/1704.05526](https://arxiv.org/abs/1704.05526)\n\n**TGIF-QA: Toward Spatio-Temporal Reasoning in Visual Question Answering**\n\n- intro: CVPR 2017.Seoul National University & Yahoo Research\n- arxiv: [https://arxiv.org/abs/1704.04497](https://arxiv.org/abs/1704.04497)\n- github: [https://github.com/YunseokJANG/tgif-qa](https://github.com/YunseokJANG/tgif-qa)\n\n**Question Answering on Knowledge Bases and Text using Universal Schema and Memory Networks**\n\n- intro: ACL 2017 (short)\n- project page: [https://rajarshd.github.io/TextKBQA/](https://rajarshd.github.io/TextKBQA/)\n- arxiv: [https://arxiv.org/abs/1704.08384](https://arxiv.org/abs/1704.08384)\n- github: [https://github.com/rajarshd/TextKBQA](https://github.com/rajarshd/TextKBQA)\n\n**Learning Convolutional Text Representations for Visual Question Answering**\n\n- arxiv: [https://arxiv.org/abs/1705.06824](https://arxiv.org/abs/1705.06824)\n- github: [https://github.com/divelab/vqa-text](https://github.com/divelab/vqa-text)\n\n## Projects\n\n**VQA Demo: Visual Question Answering Demo on pretrained model**\n\n- github: [https://github.com/iamaaditya/VQA_Demo](https://github.com/iamaaditya/VQA_Demo)\n- ref: [http://iamaaditya.github.io/research/](http://iamaaditya.github.io/research/)\n\n**deep-qa: Implementation of the Convolution Neural Network for factoid QA on the answer sentence selection task**\n\n- github: [https://github.com/aseveryn/deep-qa](https://github.com/aseveryn/deep-qa)\n\n**YodaQA: A Question Answering system built on top of the Apache UIMA framework**\n\n- homepage: [http://ailao.eu/yodaqa/](http://ailao.eu/yodaqa/)\n- github: [https://github.com/brmson/yodaqa](https://github.com/brmson/yodaqa)\n\n**insuranceQA-cnn-lstm: tensorflow and theano cnn code for insurance QA(question Answer matching)**\n\n- github: [https://github.com/white127/insuranceQA-cnn-lstm](https://github.com/white127/insuranceQA-cnn-lstm)\n\n**Tensorflow Implementation of Deeper LSTM+ normalized CNN for Visual Question Answering**\n\n![](https://cloud.githubusercontent.com/assets/19935904/16358326/e6812310-3add-11e6-914f-c61c19d6ab5a.png)\n\n- github: [https://github.com/JamesChuanggg/VQA-tensorflow](https://github.com/JamesChuanggg/VQA-tensorflow)\n\n**Visual Question Answering with Keras**\n\n![](https://camo.githubusercontent.com/f52d44199710c8f3939fb182a339d1d6a0b09a3f/687474703a2f2f692e696d6775722e636f6d2f327a4a30396d512e706e67)\n\n- project page: [https://anantzoid.github.io/VQA-Keras-Visual-Question-Answering/](https://anantzoid.github.io/VQA-Keras-Visual-Question-Answering/)\n- github: [https://github.com/anantzoid/VQA-Keras-Visual-Question-Answering](https://github.com/anantzoid/VQA-Keras-Visual-Question-Answering)\n\n**Deep Learning Models for Question Answering with Keras**\n\n- blog: [http://sujitpal.blogspot.jp/2016/10/deep-learning-models-for-question.html](http://sujitpal.blogspot.jp/2016/10/deep-learning-models-for-question.html)\n\n**GuessWhat?! Visual object discovery through multi-modal dialogue**\n\n- intro: University of Montreal & Univ. Lille & Google DeepMind & Twitter\n- arxiv: [https://arxiv.org/abs/1611.08481](https://arxiv.org/abs/1611.08481)\n\n**Deep QA: Using deep learning to answer Aristo\'s science questions**\n\n- github: [https://github.com/allenai/deep_qa](https://github.com/allenai/deep_qa)\n\n**Visual Question Answering in Pytorch**\n\n[https://github.com/Cadene/vqa.pytorch](https://github.com/Cadene/vqa.pytorch)\n\n## Dataset\n\n**Visual7W: Grounded Question Answering in Images**\n\n![](http://web.stanford.edu/~yukez/images/img/visual7w_examples.png)\n\n- homepage: [http://web.stanford.edu/~yukez/visual7w/](http://web.stanford.edu/~yukez/visual7w/)\n- github: [https://github.com/yukezhu/visual7w-toolkit](https://github.com/yukezhu/visual7w-toolkit)\n- github: [https://github.com/yukezhu/visual7w-qa-models](https://github.com/yukezhu/visual7w-qa-models)\n\n## Resources\n\n**Awesome Visual Question Answering**\n\n- github: [https://github.com/JamesChuanggg/awesome-vqa](https://github.com/JamesChuanggg/awesome-vqa)\n\n# Language Understanding\n\n**Recurrent Neural Networks with External Memory for Language Understanding**\n\n- arxiv: [http://arxiv.org/abs/1506.00195](http://arxiv.org/abs/1506.00195)\n- github: [https://github.com/npow/RNN-EM](https://github.com/npow/RNN-EM)\n\n**Neural Semantic Encoders**\n\n- intro: EACL 2017\n- arxiv: [https://arxiv.org/abs/1607.04315](https://arxiv.org/abs/1607.04315)\n- github(Keras): [https://github.com/pdasigi/neural-semantic-encoders](https://github.com/pdasigi/neural-semantic-encoders)\n\n**Neural Tree Indexers for Text Understanding**\n\n- arxiv: [https://arxiv.org/abs/1607.04492](https://arxiv.org/abs/1607.04492)\n- bitbucket: [https://bitbucket.org/tsendeemts/nti/src](https://bitbucket.org/tsendeemts/nti/src)\n\n**Better Text Understanding Through Image-To-Text Transfer**\n\n- intro: Google Brain & Technische Universität München\n- arxiv: [https://arxiv.org/abs/1705.08386](https://arxiv.org/abs/1705.08386)\n\n# Text Classification\n\n**Convolutional Neural Networks for Sentence Classification**\n\n- intro: EMNLP 2014\n- arxiv: [http://arxiv.org/abs/1408.5882](http://arxiv.org/abs/1408.5882)\n- github(Theano): [https://github.com/yoonkim/CNN_sentence](https://github.com/yoonkim/CNN_sentence)\n- github(Torch): [https://github.com/harvardnlp/sent-conv-torch](https://github.com/harvardnlp/sent-conv-torch)\n- github(Keras): [https://github.com/alexander-rakhlin/CNN-for-Sentence-Classification-in-Keras](https://github.com/alexander-rakhlin/CNN-for-Sentence-Classification-in-Keras)\n- github(Tensorflow): [https://github.com/abhaikollara/CNN-Sentence-Classification](https://github.com/abhaikollara/CNN-Sentence-Classification)\n\n**Recurrent Convolutional Neural Networks for Text Classification**\n\n- paper: [http://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/view/9745/9552](http://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/view/9745/9552)\n- github: [https://github.com/knok/rcnn-text-classification](https://github.com/knok/rcnn-text-classification)\n\n**Character-level Convolutional Networks for Text Classification**\n\n- intro: NIPS 2015. "Text Understanding from Scratch"\n- arxiv: [http://arxiv.org/abs/1509.01626](http://arxiv.org/abs/1509.01626)\n- github: [https://github.com/zhangxiangxiao/Crepe](https://github.com/zhangxiangxiao/Crepe)\n- datasets: [http://goo.gl/JyCnZq](http://goo.gl/JyCnZq)\n- github(TensorFlow): [https://github.com/mhjabreel/CharCNN](https://github.com/mhjabreel/CharCNN)\n\n**A C-LSTM Neural Network for Text Classification**\n\n- arxiv: [http://arxiv.org/abs/1511.08630](http://arxiv.org/abs/1511.08630)\n\n**Rationale-Augmented Convolutional Neural Networks for Text Classification**\n\n- arxiv: [http://arxiv.org/abs/1605.04469](http://arxiv.org/abs/1605.04469)\n\n**Text classification using DIGITS and Torch7**\n\n- github: [https://github.com/NVIDIA/DIGITS/tree/master/examples/text-classification](https://github.com/NVIDIA/DIGITS/tree/master/examples/text-classification)\n\n**Recurrent Neural Network for Text Classification with Multi-Task Learning**\n\n- arxiv: [http://arxiv.org/abs/1605.05101](http://arxiv.org/abs/1605.05101)\n\n**Deep Multi-Task Learning with Shared Memory**\n\n- intro: EMNLP 2016\n- arxiv: [https://arxiv.org/abs/1609.07222](https://arxiv.org/abs/1609.07222)\n\n**Virtual Adversarial Training for Semi-Supervised Text Classification**\n\n**Adversarial Training Methods for Semi-Supervised Text Classification**\n\n- arxiv: [http://arxiv.org/abs/1605.07725](http://arxiv.org/abs/1605.07725)\n- notes: [https://github.com/dennybritz/deeplearning-papernotes/blob/master/notes/adversarial-text-classification.md](https://github.com/dennybritz/deeplearning-papernotes/blob/master/notes/adversarial-text-classification.md)\n\n**Sentence Convolution Code in Torch: Text classification using a convolutional neural network**\n\n- github: [https://github.com/harvardnlp/sent-conv-torch](https://github.com/harvardnlp/sent-conv-torch)\n\n**Bag of Tricks for Efficient Text Classification**\n\n- intro: Facebook AI Research\n- arxiv: [http://arxiv.org/abs/1607.01759](http://arxiv.org/abs/1607.01759)\n- github: [https://github.com/kemaswill/fasttext_torch](https://github.com/kemaswill/fasttext_torch)\n- github: [https://github.com/facebookresearch/fastText](https://github.com/facebookresearch/fastText)\n\n**Actionable and Political Text Classification using Word Embeddings and LSTM**\n\n- arxiv: [http://arxiv.org/abs/1607.02501](http://arxiv.org/abs/1607.02501)\n\n**Implementing a CNN for Text Classification in TensorFlow**\n\n- blog: [http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/](http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/)\n\n**fancy-cnn: Multiparadigm Sequential Convolutional Neural Networks for text classification**\n\n- github: [https://github.com/textclf/fancy-cnn](https://github.com/textclf/fancy-cnn)\n\n**Convolutional Neural Networks for Text Categorization: Shallow Word-level vs. Deep Character-level**\n\n- arxiv: [http://arxiv.org/abs/1609.00718](http://arxiv.org/abs/1609.00718)\n\n**Tweet Classification using RNN and CNN**\n\n- github: [https://github.com/ganeshjawahar/tweet-classify](https://github.com/ganeshjawahar/tweet-classify)\n\n**Hierarchical Attention Networks for Document Classification**\n\n- intro: CMU & MSR. NAACL 2016\n- paper: [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf](https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf)\n- github(TensorFlow): [https://github.com/raviqqe/tensorflow-font2char2word2sent2doc](https://github.com/raviqqe/tensorflow-font2char2word2sent2doc)\n- github(TensorFlow): [https://github.com/ematvey/deep-text-classifier](https://github.com/ematvey/deep-text-classifier)\n\n**Generative and Discriminative Text Classification with Recurrent Neural Networks**\n\n- intro: DeepMind\n- arxiv: [https://arxiv.org/abs/1703.01898](https://arxiv.org/abs/1703.01898)\n\n**Adversarial Multi-task Learning for Text Classification**\n\n- intro: ACL 2017\n- arxiv: [https://arxiv.org/abs/1704.05742](https://arxiv.org/abs/1704.05742)\n- data: [http://nlp.fudan.edu.cn/data/](http://nlp.fudan.edu.cn/data/)\n\n**Deep Text Classification Can be Fooled**\n\n- intro: Renmin University of China\n- arxiv: [https://arxiv.org/abs/1704.08006](https://arxiv.org/abs/1704.08006)\n\n**Deep neural network framework for multi-label text classification**\n\n- github: [https://github.com/inspirehep/magpie](https://github.com/inspirehep/magpie)\n\n# Text Clustering\n\n**Self-Taught Convolutional Neural Networks for Short Text Clustering**\n\n- intro: Chinese Academy of Sciences. accepted for publication in Neural Networks\n- arxiv: [https://arxiv.org/abs/1701.00185](https://arxiv.org/abs/1701.00185)\n- github: [https://github.com/jacoxu/STC2](https://github.com/jacoxu/STC2)\n\n# Alignment\n\n**Aligning Books and Movies: Towards Story-like Visual Explanations by Watching Movies and Reading Books**\n\n- arxiv: [http://arxiv.org/abs/1506.06724](http://arxiv.org/abs/1506.06724)\n- github: [https://github.com/ryankiros/neural-storyteller](https://github.com/ryankiros/neural-storyteller)\n\n# Dialog\n\n**Visual Dialog**\n\n- webiste: [http://visualdialog.org/](http://visualdialog.org/)\n- arxiv: [https://arxiv.org/abs/1611.08669](https://arxiv.org/abs/1611.08669)\n- github: [https://github.com/batra-mlp-lab/visdial-amt-chat](https://github.com/batra-mlp-lab/visdial-amt-chat)\n- github(Torch): [https://github.com/batra-mlp-lab/visdial](https://github.com/batra-mlp-lab/visdial)\n- github(PyTorch): [https://github.com/Cloud-CV/visual-chatbot](https://github.com/Cloud-CV/visual-chatbot)\n- demo: [http://visualchatbot.cloudcv.org/](http://visualchatbot.cloudcv.org/)\n\n**Papers, code and data from FAIR for various memory-augmented nets with application to text understanding and dialogue.**\n\n- post: [https://www.facebook.com/yann.lecun/posts/10154070851697143](https://www.facebook.com/yann.lecun/posts/10154070851697143)\n\n**Neural Emoji Recommendation in Dialogue Systems**\n\n- intro: Tsinghua University & Baidu\n- arxiv: [https://arxiv.org/abs/1612.04609](https://arxiv.org/abs/1612.04609)\n\n# Memory Networks\n\n**Neural Turing Machines**\n\n- paper: [http://arxiv.org/abs/1410.5401](http://arxiv.org/abs/1410.5401)\n- Chs: [http://www.jianshu.com/p/94dabe29a43b](http://www.jianshu.com/p/94dabe29a43b)\n- github: [https://github.com/shawntan/neural-turing-machines](https://github.com/shawntan/neural-turing-machines)\n- github: [https://github.com/DoctorTeeth/diffmem](https://github.com/DoctorTeeth/diffmem)\n- github: [https://github.com/carpedm20/NTM-tensorflow](https://github.com/carpedm20/NTM-tensorflow)\n- blog: [https://blog.aidangomez.ca/2016/05/16/The-Neural-Turing-Machine/](https://blog.aidangomez.ca/2016/05/16/The-Neural-Turing-Machine/)\n\n**Memory Networks**\n\n- intro: Facebook AI Research\n- arxiv: [http://arxiv.org/abs/1410.3916](http://arxiv.org/abs/1410.3916)\n- github: [https://github.com/npow/MemNN](https://github.com/npow/MemNN)\n\n**End-To-End Memory Networks**\n\n- intro: Facebook AI Research\n- intro: Continuous version of memory extraction via softmax. "Weakly supervised memory networks"\n- arxiv: [http://arxiv.org/abs/1503.08895](http://arxiv.org/abs/1503.08895)\n- github: [https://github.com/facebook/MemNN](https://github.com/facebook/MemNN)\n- github: [https://github.com/vinhkhuc/MemN2N-babi-python](https://github.com/vinhkhuc/MemN2N-babi-python)\n- github: [https://github.com/npow/MemN2N](https://github.com/npow/MemN2N)\n- github: [https://github.com/domluna/memn2n](https://github.com/domluna/memn2n)\n- github(Tensorflow): [https://github.com/abhaikollara/MemN2N-Tensorflow](https://github.com/abhaikollara/MemN2N-Tensorflow)\n- video: [http://research.microsoft.com/apps/video/default.aspx?id=259920&r=1](http://research.microsoft.com/apps/video/default.aspx?id=259920&r=1)\n- video: [http://pan.baidu.com/s/1pKiGLzP](http://pan.baidu.com/s/1pKiGLzP)\n\n**Reinforcement Learning Neural Turing Machines - Revised**\n\n- arxiv: [http://arxiv.org/abs/1505.00521](http://arxiv.org/abs/1505.00521)\n- github: [https://github.com/ilyasu123/rlntm](https://github.com/ilyasu123/rlntm)\n\n- - -\n\n**Learning to Transduce with Unbounded Memory**\n\n- intro: Google DeepMind\n- arxiv: [http://arxiv.org/abs/1506.02516](http://arxiv.org/abs/1506.02516)\n\n**How to Code and Understand DeepMind\'s Neural Stack Machine**\n\n- blog: [https://iamtrask.github.io/2016/02/25/deepminds-neural-stack-machine/](https://iamtrask.github.io/2016/02/25/deepminds-neural-stack-machine/)\n- video tutorial: [http://pan.baidu.com/s/1qX0EGDe](http://pan.baidu.com/s/1qX0EGDe)\n\n- - -\n\n**Ask Me Anything: Dynamic Memory Networks for Natural Language Processing**\n\n- intro: Memory networks implemented via rnns and gated recurrent units (GRUs).\n- arxiv: [http://arxiv.org/abs/1506.07285](http://arxiv.org/abs/1506.07285)\n- blog("Implementing Dynamic memory networks"): [http://yerevann.github.io//2016/02/05/implementing-dynamic-memory-networks/](http://yerevann.github.io//2016/02/05/implementing-dynamic-memory-networks/)\n- github(Python): [https://github.com/swstarlab/DynamicMemoryNetworks](https://github.com/swstarlab/DynamicMemoryNetworks)\n\n**Ask Me Even More: Dynamic Memory Tensor Networks (Extended Model)**\n\n- intro: extensions for the Dynamic Memory Network (DMN)\n- arxiv: [https://arxiv.org/abs/1703.03939](https://arxiv.org/abs/1703.03939)\n- github: [https://github.com/rgsachin/DMTN](https://github.com/rgsachin/DMTN)\n\n**Structured Memory for Neural Turing Machines**\n\n- intro: IBM Watson\n- arxiv: [http://arxiv.org/abs/1510.03931](http://arxiv.org/abs/1510.03931)\n\n**Dynamic Memory Networks for Visual and Textual Question Answering**\n\n![](https://camo.githubusercontent.com/0f17be4fe54c583cf7b5ef5387ac363e0cd87f92/687474703a2f2f692e696d6775722e636f6d2f33304465504b682e706e67)\n\n- intro: MetaMind 2016\n- arxiv: [http://arxiv.org/abs/1603.01417](http://arxiv.org/abs/1603.01417)\n- slides: [http://slides.com/smerity/dmn-for-tqa-and-vqa-nvidia-gtc#/](http://slides.com/smerity/dmn-for-tqa-and-vqa-nvidia-gtc#/)\n- github: [https://github.com/therne/dmn-tensorflow](https://github.com/therne/dmn-tensorflow)\n- github(Theano): [https://github.com/ethancaballero/Improved-Dynamic-Memory-Networks-DMN-plus](https://github.com/ethancaballero/Improved-Dynamic-Memory-Networks-DMN-plus)\n- review: [https://www.technologyreview.com/s/600958/the-memory-trick-making-computers-seem-smarter/](https://www.technologyreview.com/s/600958/the-memory-trick-making-computers-seem-smarter/)\n- github(Tensorflow): [https://github.com/DeepRNN/visual_question_answering](https://github.com/DeepRNN/visual_question_answering)\n\n**Neural GPUs Learn Algorithms**\n\n- arxiv: [http://arxiv.org/abs/1511.08228](http://arxiv.org/abs/1511.08228)\n- github: [https://github.com/tensorflow/models/tree/master/neural_gpu](https://github.com/tensorflow/models/tree/master/neural_gpu)\n- github: [https://github.com/ikostrikov/torch-neural-gpu](https://github.com/ikostrikov/torch-neural-gpu)\n- github: [https://github.com/tristandeleu/neural-gpu](https://github.com/tristandeleu/neural-gpu)\n\n**Hierarchical Memory Networks**\n\n- arxiv: [http://arxiv.org/abs/1605.07427](http://arxiv.org/abs/1605.07427)\n\n**Convolutional Residual Memory Networks**\n\n- arxiv: [http://arxiv.org/abs/1606.05262](http://arxiv.org/abs/1606.05262)\n\n**NTM-Lasagne: A Library for Neural Turing Machines in Lasagne**\n\n- github: [https://github.com/snipsco/ntm-lasagne](https://github.com/snipsco/ntm-lasagne)\n- blog: [https://medium.com/snips-ai/ntm-lasagne-a-library-for-neural-turing-machines-in-lasagne-2cdce6837315#.96pnh1m6j](https://medium.com/snips-ai/ntm-lasagne-a-library-for-neural-turing-machines-in-lasagne-2cdce6837315#.96pnh1m6j)\n\n**Evolving Neural Turing Machines for Reward-based Learning**\n\n- homepage: [http://sebastianrisi.com/entm/](http://sebastianrisi.com/entm/)\n- paper: [http://sebastianrisi.com/wp-content/uploads/greve_gecco16.pdf](http://sebastianrisi.com/wp-content/uploads/greve_gecco16.pdf)\n- code: [https://www.dropbox.com/s/t019mwabw5nsnxf/neuralturingmachines-master.zip?dl=0](https://www.dropbox.com/s/t019mwabw5nsnxf/neuralturingmachines-master.zip?dl=0)\n\n**Hierarchical Memory Networks for Answer Selection on Unknown Words**\n\n- intro: COLING 2016\n- arxiv: [https://arxiv.org/abs/1609.08843](https://arxiv.org/abs/1609.08843)\n- github: [https://github.com/jacoxu/HMN4QA](https://github.com/jacoxu/HMN4QA)\n\n**Gated End-to-End Memory Networks**\n\n- arxiv: [https://arxiv.org/abs/1610.04211](https://arxiv.org/abs/1610.04211)\n\n**Can Active Memory Replace Attention?**\n\n- intro: Google Brain\n- arxiv: [https://arxiv.org/abs/1610.08613](https://arxiv.org/abs/1610.08613)\n\n# Papers\n\n**Globally Normalized Transition-Based Neural Networks**\n\n![](https://raw.githubusercontent.com/tensorflow/models/master/syntaxnet/looping-parser.gif)\n\n- intro: speech tagging, dependency parsing and sentence compression \n- arxiv: [http://arxiv.org/abs/1603.06042](http://arxiv.org/abs/1603.06042)\n- github(SyntaxNet): [https://github.com/tensorflow/models/tree/master/syntaxnet](https://github.com/tensorflow/models/tree/master/syntaxnet)\n\n**A Decomposable Attention Model for Natural Language Inference**\n\n- intro: EMNLP 2016\n- arxiv: [http://arxiv.org/abs/1606.01933](http://arxiv.org/abs/1606.01933)\n- github(Keras+spaCy): [https://github.com/explosion/spaCy/tree/master/examples/keras_parikh_entailment](https://github.com/explosion/spaCy/tree/master/examples/keras_parikh_entailment)\n\n**Improving Recurrent Neural Networks For Sequence Labelling**\n\n- arxiv: [http://arxiv.org/abs/1606.02555](http://arxiv.org/abs/1606.02555)\n\n**Recurrent Memory Networks for Language Modeling**\n\n- arixv: [http://arxiv.org/abs/1601.01272](http://arxiv.org/abs/1601.01272)\n- github: [https://github.com/ketranm/RMN](https://github.com/ketranm/RMN)\n\n**Tweet2Vec: Learning Tweet Embeddings Using Character-level CNN-LSTM Encoder-Decoder**\n\n- intro: MIT Media Lab\n- arixv: [http://arxiv.org/abs/1607.07514](http://arxiv.org/abs/1607.07514)\n\n**Learning text representation using recurrent convolutional neural network with highway layers**\n\n- intro: Neu-IR \'16 SIGIR Workshop on Neural Information Retrieval\n- arxiv: [http://arxiv.org/abs/1606.06905](http://arxiv.org/abs/1606.06905)\n- github: [https://github.com/wenying45/deep_learning_tutorial/tree/master/rcnn-hw](https://github.com/wenying45/deep_learning_tutorial/tree/master/rcnn-hw)\n\n**Ask the GRU: Multi-task Learning for Deep Text Recommendations**\n\n- arxiv: [http://arxiv.org/abs/1609.02116](http://arxiv.org/abs/1609.02116)\n\n**From phonemes to images: levels of representation in a recurrent neural model of visually-grounded language learning**\n\n- intro: COLING 2016\n- arxiv: [https://arxiv.org/abs/1610.03342](https://arxiv.org/abs/1610.03342)\n\n**Visualizing Linguistic Shift**\n\n- arxiv: [https://arxiv.org/abs/1611.06478](https://arxiv.org/abs/1611.06478)\n\n**A Joint Many-Task Model: Growing a Neural Network for Multiple NLP Tasks**\n\n- intro: The University of Tokyo & Salesforce Research\n- arxiv: [https://arxiv.org/abs/1611.01587](https://arxiv.org/abs/1611.01587)\n\n**Deep Learning applied to NLP**\n\n[https://arxiv.org/abs/1703.03091](https://arxiv.org/abs/1703.03091)\n\n**Attention Is All You Need**\n\n- intro: Google Brain & Google Research & University of Toronto\n- intro: Just attention + positional encoding = state of the art\n- arxiv: [https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762)\n- github(Chainer): [https://github.com/soskek/attention_is_all_you_need](https://github.com/soskek/attention_is_all_you_need)\n\n## Interesting Applications\n\n**Data-driven HR - Résumé Analysis Based on Natural Language Processing and Machine Learning**\n\n- arxiv: [http://arxiv.org/abs/1606.05611](http://arxiv.org/abs/1606.05611)\n\n**sk_p: a neural program corrector for MOOCs**\n\n- intro: MIT\n- intro: Using seq2seq to fix buggy code submissions in MOOCs\n- arxiv: [http://arxiv.org/abs/1607.02902](http://arxiv.org/abs/1607.02902)\n\n**Neural Generation of Regular Expressions from Natural Language with Minimal Domain Knowledge**\n\n- intro: EMNLP 2016\n- intro: translating natural language queries into regular expressions which embody their meaning\n- arxiv: [http://arxiv.org/abs/1608.03000](http://arxiv.org/abs/1608.03000)\n\n**emoji2vec: Learning Emoji Representations from their Description**\n\n- intro: EMNLP 2016\n- arxiv: [http://arxiv.org/abs/1609.08359](http://arxiv.org/abs/1609.08359)\n\n**Inside-Outside and Forward-Backward Algorithms Are Just Backprop (Tutorial Paper)**\n\n- paper: [https://www.cs.jhu.edu/~jason/papers/eisner.spnlp16.pdf](https://www.cs.jhu.edu/~jason/papers/eisner.spnlp16.pdf)\n\n**Cruciform: Solving Crosswords with Natural Language Processing**\n\n- arxiv: [https://arxiv.org/abs/1611.02360](https://arxiv.org/abs/1611.02360)\n\n**Smart Reply: Automated Response Suggestion for Email**\n\n- intro: Google. KDD 2016\n- arxiv: [https://arxiv.org/abs/1606.04870](https://arxiv.org/abs/1606.04870)\n- notes: [https://blog.acolyer.org/2016/11/24/smart-reply-automated-response-suggestion-for-email/](https://blog.acolyer.org/2016/11/24/smart-reply-automated-response-suggestion-for-email/)\n\n**Deep Learning for RegEx**\n\n- intro: a winning submission of *Extraction of product attribute values* competition (CrowdAnalytix)\n- blog: [http://dlacombejr.github.io/2016/11/13/deep-learning-for-regex.html](http://dlacombejr.github.io/2016/11/13/deep-learning-for-regex.html)\n\n**Learning Python Code Suggestion with a Sparse Pointer Network**\n\n- intro: Learning to Auto-Complete using RNN Language Models\n- intro: University College London\n- arxiv: [https://arxiv.org/abs/1611.08307](https://arxiv.org/abs/1611.08307)\n- github: [https://github.com/uclmr/pycodesuggest](https://github.com/uclmr/pycodesuggest)\n\n**End-to-End Prediction of Buffer Overruns from Raw Source Code via Neural Memory Networks**\n\n[https://arxiv.org/abs/1703.02458](https://arxiv.org/abs/1703.02458)\n\n**Convolutional Sequence to Sequence Learning**\n\n- arxiv: [https://arxiv.org/abs/1705.03122](https://arxiv.org/abs/1705.03122)\n- paper: [https://s3.amazonaws.com/fairseq/papers/convolutional-sequence-to-sequence-learning.pdf](https://s3.amazonaws.com/fairseq/papers/convolutional-sequence-to-sequence-learning.pdf)\n- github: [https://github.com/facebookresearch/fairseq](https://github.com/facebookresearch/fairseq)\n\n**DeepFix: Fixing Common C Language Errors by Deep Learning**\n\n- intro: AAAI 2017. Indian Institute of Science\n- project page: [http://www.iisc-seal.net/deepfix](http://www.iisc-seal.net/deepfix)\n- paper: [https://www.aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14603/13921](https://www.aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14603/13921)\n- bitbucket: [https://bitbucket.org/iiscseal/deepfix](https://bitbucket.org/iiscseal/deepfix)\n\n# Project\n\n**TheanoLM - An Extensible Toolkit for Neural Network Language Modeling**\n\n- arxiv: [http://arxiv.org/abs/1605.00942](http://arxiv.org/abs/1605.00942)\n- github: [https://github.com/senarvi/theanolm](https://github.com/senarvi/theanolm)\n\n**NLP-Caffe: natural language processing with Caffe**\n\n- github: [https://github.com/Russell91/nlpcaffe](https://github.com/Russell91/nlpcaffe)\n\n**DL4NLP: Deep Learning for Natural Language Processing**\n\n- github: [https://github.com/nokuno/dl4nlp](https://github.com/nokuno/dl4nlp)\n\n**Combining CNN and RNN for spoken language identification**\n\n- blog: [http://yerevann.github.io//2016/06/26/combining-cnn-and-rnn-for-spoken-language-identification/](http://yerevann.github.io//2016/06/26/combining-cnn-and-rnn-for-spoken-language-identification/)\n- github: [https://github.com/YerevaNN/Spoken-language-identification/tree/master/theano](https://github.com/YerevaNN/Spoken-language-identification/tree/master/theano)\n\n**Character-Aware Neural Language Models: LSTM language model with CNN over characters in TensorFlow**\n\n- github: [https://github.com/carpedm20/lstm-char-cnn-tensorflow](https://github.com/carpedm20/lstm-char-cnn-tensorflow)\n\n**Neural Relation Extraction with Selective Attention over Instances**\n\n- paper: [http://nlp.csai.tsinghua.edu.cn/~lzy/publications/acl2016_nre.pdf](http://nlp.csai.tsinghua.edu.cn/~lzy/publications/acl2016_nre.pdf)\n- github: [https://github.com/thunlp/NRE](https://github.com/thunlp/NRE)\n\n**deep-simplification: Text simplification using RNNs**\n\n- intro: achieves a BLEU score of 61.14\n- github: [https://github.com/mbartoli/deep-simplification](https://github.com/mbartoli/deep-simplification)\n\n**lamtram: A toolkit for language and translation modeling using neural networks**\n\n- github: [https://github.com/neubig/lamtram](https://github.com/neubig/lamtram)\n\n**Lango: Language Lego**\n\n- intro: Lango is a natural language processing library for working with the building blocks of language.\n- github: [https://github.com/ayoungprogrammer/Lango](https://github.com/ayoungprogrammer/Lango)\n\n**Sequence-to-Sequence Learning with Attentional Neural Networks**\n\n- github(Torch): [https://github.com/harvardnlp/seq2seq-attn](https://github.com/harvardnlp/seq2seq-attn)\n\n**harvardnlp code**\n\n- intro: pen-source implementations of popular deep learning techniques with applications to NLP\n- homepage: [http://nlp.seas.harvard.edu/code/](http://nlp.seas.harvard.edu/code/)\n\n**Seq2seq: Sequence to Sequence Learning with Keras**\n\n![](https://camo.githubusercontent.com/242210d7d0151cae91107ee63bff364a860db5dd/687474703a2f2f6936342e74696e797069632e636f6d2f333031333674652e706e67)\n\n- github: [https://github.com/farizrahman4u/seq2seq](https://github.com/farizrahman4u/seq2seq)\n\n**debug seq2seq**\n\n- github: [https://github.com/nicolas-ivanov/debug_seq2seq](https://github.com/nicolas-ivanov/debug_seq2seq)\n\n**Recurrent & convolutional neural network modules**\n\n- intro: This repo contains Theano implementations of popular neural network components and optimization methods.\n- github: [https://github.com/taolei87/rcnn](https://github.com/taolei87/rcnn)\n\n# Datasets\n\n**Datasets for Natural Language Processing**\n\n- github: [https://github.com/karthikncode/nlp-datasets](https://github.com/karthikncode/nlp-datasets)\n\n# Blogs\n\n**How to read: Character level deep learning**\n\n![](https://raw.githubusercontent.com/offbit/offbit.github.io/master/assets/char-models/fullmodel.jpg)\n\n- blog: [https://offbit.github.io/how-to-read/](https://offbit.github.io/how-to-read/)\n- github: [https://github.com/offbit/char-models](https://github.com/offbit/char-models)\n\n**Heavy Metal and Natural Language Processing**\n\n- part 1: [http://www.degeneratestate.org/posts/2016/Apr/20/heavy-metal-and-natural-language-processing-part-1/](http://www.degeneratestate.org/posts/2016/Apr/20/heavy-metal-and-natural-language-processing-part-1/)\n\n**Sequence To Sequence Attention Models In PyCNN**\n\n[https://talbaumel.github.io/Neural+Attention+Mechanism.html](https://talbaumel.github.io/Neural+Attention+Mechanism.html)\n\n**Source Code Classification Using Deep Learning**\n\n![](http://blog.aylien.com/wp-content/uploads/2016/08/cnn_source_code_model.png)\n\n[http://blog.aylien.com/source-code-classification-using-deep-learning/](http://blog.aylien.com/source-code-classification-using-deep-learning/)\n\n**My Process for Learning Natural Language Processing with Deep Learning**\n\n[https://medium.com/@MichaelTeifel/my-process-for-learning-natural-language-processing-with-deep-learning-bd0a64a36086](https://medium.com/@MichaelTeifel/my-process-for-learning-natural-language-processing-with-deep-learning-bd0a64a36086)\n\n**Convolutional Methods for Text**\n\n[https://medium.com/@TalPerry/convolutional-methods-for-text-d5260fd5675f](https://medium.com/@TalPerry/convolutional-methods-for-text-d5260fd5675f)\n\n## Word2Vec\n\n**Word2Vec Tutorial - The Skip-Gram Model**\n\n[http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/)\n\n**Word2Vec Tutorial Part 2 - Negative Sampling**\n\n[http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/](http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/)\n\n**Word2Vec Resources**\n\n[http://mccormickml.com/2016/04/27/word2vec-resources/](http://mccormickml.com/2016/04/27/word2vec-resources/)\n\n# Demos\n\n**AskImage.org - Deep Learning for Answering Questions about Images**\n\n- homepage: [http://www.askimage.org/](http://www.askimage.org/)\n\n# Talks / Videos\n\n**Navigating Natural Language Using Reinforcement Learning**\n\n- youtube: [https://www.youtube.com/watch?v=7s-erJbCkaY](https://www.youtube.com/watch?v=7s-erJbCkaY)\n\n# Resources\n\n**So, you need to understand language data? Open-source NLP software can help!**\n\n![](http://entopix.com/assets/white-paper/slide1.png)\n\n- blog: [http://entopix.com/so-you-need-to-understand-language-data-open-source-nlp-software-can-help.html](http://entopix.com/so-you-need-to-understand-language-data-open-source-nlp-software-can-help.html)\n\n**Curated list of resources on building bots**\n\n![](https://raw.githubusercontent.com/hackerkid/bots/master/bots3d.png)\n\n- github: [https://github.com/hackerkid/bots](https://github.com/hackerkid/bots)\n\n**Notes for deep learning on NLP**\n\n[https://medium.com/@frank_chung/notes-for-deep-learning-on-nlp-94ddfcb45723#.iouo0v7m7](https://medium.com/@frank_chung/notes-for-deep-learning-on-nlp-94ddfcb45723#.iouo0v7m7)',
metaData:{layout:"post",title:"Deep learning for NLP",excerpt:"近两年的优秀论文",category:"research",tags:["nlp","nlu","qna"],disqus:!0}}}});